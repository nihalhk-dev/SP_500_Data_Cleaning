{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5790005",
   "metadata": {},
   "source": [
    "# S&P 500 – Processed Dataset Validation & Analysis\n",
    "\n",
    "This notebook represents the final validation stage of the data pipeline.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "1. Load and inspect the processed dataset  \n",
    "2. Validate dataset structure and integrity  \n",
    "3. Explain rolling-feature NaN behavior  \n",
    "4. Confirm chronological correctness  \n",
    "5. Analyze price dynamics  \n",
    "6. Evaluate return properties and distribution  \n",
    "7. Study moving averages as trend indicators  \n",
    "8. Examine rolling volatility as a risk measure  \n",
    "9. Measure cumulative performance  \n",
    "10. Quantify downside risk using Maximum Drawdown  \n",
    "11. Compute annualized volatility  \n",
    "12. Evaluate risk-adjusted performance using the Sharpe Ratio  \n",
    "13. Analyze time-varying performance with Rolling Sharpe Ratio  \n",
    "14. Examine relationships between engineered features (Correlation Matrix)  \n",
    "15. Conduct statistical testing (ADF stationarity test and Jarque-Bera normality test)\n",
    "\n",
    "The dataset at this stage is fully cleaned and feature-engineered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e72cba",
   "metadata": {},
   "source": [
    "## 1. Load Processed Dataset\n",
    "\n",
    "We load the cleaned dataset and ensure correct datetime formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/sp500_clean.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "df['Return'] = df['Price'].pct_change()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ba92d",
   "metadata": {},
   "source": [
    "## 2. Dataset Structure & Integrity\n",
    "\n",
    "We validate:\n",
    "\n",
    "- Data types\n",
    "- Summary statistics\n",
    "- Missing values\n",
    "- Duplicate rows\n",
    "\n",
    "This ensures the preprocessing pipeline executed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c93901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24734ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb401209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3950cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dfbad6",
   "metadata": {},
   "source": [
    "## 3. Rolling Features and NaN Behavior\n",
    "\n",
    "The dataset contains NaN values in:\n",
    "\n",
    "- MA_20\n",
    "- MA_50\n",
    "- Volatility_20\n",
    "\n",
    "These are mathematically expected.\n",
    "\n",
    "### Moving Averages\n",
    "\n",
    "A rolling window of size N requires N observations.\n",
    "\n",
    "- MA_20 → first valid value at index 19\n",
    "- MA_50 → first valid value at index 49\n",
    "\n",
    "Thus:\n",
    "- MA_20 has 19 NaNs\n",
    "- MA_50 has 49 NaNs\n",
    "\n",
    "### Volatility\n",
    "\n",
    "Volatility is calculated as a rolling standard deviation of returns.\n",
    "\n",
    "Because:\n",
    "- The first return is NaN (no prior price),\n",
    "- And 20 valid returns are required,\n",
    "\n",
    "The first valid volatility appears at index 20.\n",
    "\n",
    "Therefore:\n",
    "- Volatility_20 has 20 NaNs\n",
    "\n",
    "These values confirm correct rolling implementation.\n",
    "They are not data errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe10bd",
   "metadata": {},
   "source": [
    "The early rows confirm:\n",
    "\n",
    "- Return is NaN only at the first observation\n",
    "- MA_20 appears at index 19\n",
    "- Volatility_20 appears at index 20\n",
    "- MA_50 appears at index 49\n",
    "\n",
    "Rolling logic is implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8172827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87919b",
   "metadata": {},
   "source": [
    "Final rows contain no NaNs in rolling features.\n",
    "\n",
    "This confirms:\n",
    "\n",
    "- No unintended truncation\n",
    "- Full time coverage\n",
    "- Stable feature computation across the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4a550",
   "metadata": {},
   "source": [
    "## 4. Chronological Order\n",
    "\n",
    "Time-series calculations require strictly ordered observations.\n",
    "\n",
    "Incorrect sorting would distort:\n",
    "\n",
    "- Returns\n",
    "- Moving averages\n",
    "- Volatility\n",
    "\n",
    "We verify ordering below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefff855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Date']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5660800",
   "metadata": {},
   "source": [
    "## 5. Price Dynamics\n",
    "\n",
    "The S&P 500 price series exhibits:\n",
    "\n",
    "- Long-term upward drift\n",
    "- Cyclical corrections\n",
    "- Periods of structural volatility\n",
    "\n",
    "Prices are non-stationary.\n",
    "Therefore, financial modeling relies primarily on returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df['Date'], df['Price'])\n",
    "plt.title(\"S&P 500 Price Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df['Price'], bins=50)\n",
    "plt.title(\"Price Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Price Summary Statistics\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Mean:\", round(df['Price'].mean(),2))\n",
    "print(\"Std Dev:\", round(df['Price'].std(),2))\n",
    "print(\"Max:\", round(df['Price'].max(),2))\n",
    "print(\"Min:\", round(df['Price'].min(),2))\n",
    "print(\"Skewness:\", round(df['Price'].skew(),2))\n",
    "print(\"Kurtosis:\", round(df['Price'].kurt(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0b66a",
   "metadata": {},
   "source": [
    "## 6. Return Properties\n",
    "\n",
    "Returns are computed as:\n",
    "\n",
    "Return_t = (Price_t / Price_{t-1}) - 1\n",
    "\n",
    "Properties:\n",
    "\n",
    "- Centered near zero\n",
    "- More stationary than prices\n",
    "- Capture daily market fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc169f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df['Date'], df['Return'])\n",
    "plt.title(\"Daily Returns\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df['Return'].dropna(), bins=50)\n",
    "plt.title(\"Return Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72218d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Return Summary Statistics\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Mean:\", round(df['Return'].mean(), 6))\n",
    "print(\"Std Dev:\", round(df['Return'].std(), 4))\n",
    "print(\"Max:\", round(df['Return'].max(), 4))\n",
    "print(\"Min:\", round(df['Return'].min(), 4))\n",
    "print(\"Skewness:\", round(df['Return'].skew(), 4))\n",
    "print(\"Kurtosis:\", round(df['Return'].kurt(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec84a99e",
   "metadata": {},
   "source": [
    "## 7. Moving Averages\n",
    "\n",
    "Moving averages smooth short-term fluctuations.\n",
    "\n",
    "- MA_20 → short-term trend\n",
    "- MA_50 → medium-term trend\n",
    "\n",
    "Crossovers may indicate regime shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fade1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df['Date'], df['Price'], label='Price')\n",
    "plt.plot(df['Date'], df['MA_20'], label='MA 20')\n",
    "plt.plot(df['Date'], df['MA_50'], label='MA 50')\n",
    "plt.legend()\n",
    "plt.title(\"Price with Moving Averages\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1b630",
   "metadata": {},
   "source": [
    "## 8. Rolling Volatility\n",
    "\n",
    "Volatility measures dispersion of returns and approximates short-term risk.\n",
    "\n",
    "The 20-day rolling standard deviation captures local market uncertainty.\n",
    "\n",
    "Spikes typically align with:\n",
    "\n",
    "- Market stress\n",
    "- Economic shocks\n",
    "- Financial crises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeca31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df['Date'], df['Volatility_20'])\n",
    "plt.title(\"20-Day Rolling Volatility\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546e6286",
   "metadata": {},
   "source": [
    "## 9. Cumulative Return\n",
    "\n",
    "Cumulative return simulates the growth of $1 invested.\n",
    "\n",
    "Computed as:\n",
    "\n",
    "(1 + Return).cumprod()\n",
    "\n",
    "This reflects long-term index performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ccc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cumulative_Return'] = (1 + df['Return']).cumprod()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df['Date'], df['Cumulative_Return'])\n",
    "plt.title(\"Cumulative Growth of $1 Invested\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8ec7e",
   "metadata": {},
   "source": [
    "## 10. Maximum Drawdown\n",
    "\n",
    "Maximum Drawdown (MDD) measures the largest peak-to-trough decline \n",
    "in cumulative returns.\n",
    "\n",
    "It represents the worst historical loss an investor would have experienced.\n",
    "\n",
    "Formula:\n",
    "\n",
    "Drawdown_t = (Cumulative_t - Rolling_Max_t) / Rolling_Max_t\n",
    "\n",
    "Maximum Drawdown = minimum(drawdown)\n",
    "\n",
    "This is a key downside risk metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c18208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rolling_Max'] = df['Cumulative_Return'].cummax()\n",
    "\n",
    "df['Drawdown'] = (\n",
    "    df['Cumulative_Return'] - df['Rolling_Max']\n",
    ") / df['Rolling_Max']\n",
    "\n",
    "max_drawdown = df['Drawdown'].min()\n",
    "\n",
    "print(\"Maximum Drawdown:\", round(max_drawdown, 4))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df['Date'], df['Drawdown'])\n",
    "plt.title(\"Drawdown Over Time\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268d7c7",
   "metadata": {},
   "source": [
    "## 11. Annualized Volatility\n",
    "\n",
    "Annualized volatility scales daily standard deviation to yearly terms.\n",
    "\n",
    "Assuming 252 trading days:\n",
    "\n",
    "Annualized Volatility = daily_std × sqrt(252)\n",
    "\n",
    "This reflects annualized market risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "daily_vol = df['Return'].std()\n",
    "annual_vol = daily_vol * np.sqrt(252)\n",
    "\n",
    "print(\"Annualized Volatility:\", round(annual_vol, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00adf81",
   "metadata": {},
   "source": [
    "## 12. Sharpe Ratio\n",
    "\n",
    "The Sharpe Ratio measures risk-adjusted return.\n",
    "\n",
    "Sharpe = (Mean Return - Risk-Free Rate) / Volatility\n",
    "\n",
    "For simplicity, we assume risk-free rate = 0.\n",
    "\n",
    "Annualized Sharpe:\n",
    "(mean_daily × 252) / (daily_std × sqrt(252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_daily = df['Return'].mean()\n",
    "\n",
    "annual_return = mean_daily * 252\n",
    "annual_vol = df['Return'].std() * np.sqrt(252)\n",
    "\n",
    "sharpe_ratio = annual_return / annual_vol\n",
    "\n",
    "print(\"Annualized Sharpe Ratio:\", round(sharpe_ratio, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b528936",
   "metadata": {},
   "source": [
    "## 13. Rolling Sharpe Ratio\n",
    "\n",
    "Rolling Sharpe measures time-varying risk-adjusted performance.\n",
    "\n",
    "We compute a 252-day rolling Sharpe ratio \n",
    "(approximate 1 trading year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = df['Return'].rolling(252).mean()\n",
    "rolling_std = df['Return'].rolling(252).std()\n",
    "\n",
    "df['Rolling_Sharpe'] = (\n",
    "    rolling_mean * 252\n",
    ") / (rolling_std * np.sqrt(252))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df['Date'], df['Rolling_Sharpe'])\n",
    "plt.title(\"Rolling 1-Year Sharpe Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a87bc73",
   "metadata": {},
   "source": [
    "## 14. Correlation Matrix\n",
    "\n",
    "We examine relationships between engineered features:\n",
    "\n",
    "- Return\n",
    "- MA_20\n",
    "- MA_50\n",
    "- Volatility_20\n",
    "\n",
    "This helps detect redundancy and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb32566",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[['Return', 'MA_20', 'MA_50', 'Volatility_20']].corr()\n",
    "\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ff9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(corr, cmap='coolwarm', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=45)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a8ca5",
   "metadata": {},
   "source": [
    "## 15. Statistical Testing\n",
    "\n",
    "To formally validate the statistical properties of the dataset, we conduct:\n",
    "\n",
    "1. **Augmented Dickey-Fuller (ADF) Test** for stationarity  \n",
    "2. **Jarque-Bera (JB) Test** for normality  \n",
    "\n",
    "These tests provide formal statistical evidence supporting the visual and descriptive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import jarque_bera\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "adf_price = adfuller(df['Price'].dropna())\n",
    "adf_return = adfuller(df['Return'].dropna())\n",
    "\n",
    "print(\"ADF Test Results\")\n",
    "print(\"----------------\")\n",
    "print(\"Price p-value:\", adf_price[1])\n",
    "print(\"Return p-value:\", adf_return[1])\n",
    "\n",
    "\n",
    "jb_stat, jb_pvalue = jarque_bera(df['Return'].dropna())\n",
    "\n",
    "print(\"\\nJarque-Bera Test\")\n",
    "print(\"----------------\")\n",
    "print(\"JB p-value:\", jb_pvalue)\n",
    "\n",
    "\n",
    "sm.qqplot(df['Return'].dropna(), line='s')\n",
    "plt.title(\"QQ Plot of Returns\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79686b39",
   "metadata": {},
   "source": [
    "### Statistical Test Results Interpretation\n",
    "\n",
    "#### Augmented Dickey-Fuller (ADF) Test\n",
    "\n",
    "Price p-value: 0.5050  \n",
    "Return p-value: 4.96e-29  \n",
    "\n",
    "At the 5% significance level:\n",
    "\n",
    "- The p-value for **Price** is greater than 0.05.  \n",
    "  We fail to reject the null hypothesis of a unit root.  \n",
    "  → The price series is **non-stationary**.\n",
    "\n",
    "- The p-value for **Return** is far below 0.05.  \n",
    "  We reject the null hypothesis of a unit root.  \n",
    "  → The return series is **stationary**.\n",
    "\n",
    "This confirms a fundamental property of financial markets:\n",
    "- Asset prices follow a non-stationary process.\n",
    "- Returns are stationary and suitable for statistical modeling.\n",
    "\n",
    "\n",
    "\n",
    "#### Jarque-Bera Test for Normality\n",
    "\n",
    "JB p-value: 0.0  \n",
    "\n",
    "The p-value is effectively zero (p < 0.05), therefore:\n",
    "\n",
    "We reject the null hypothesis of normality.\n",
    "\n",
    "This indicates that S&P 500 returns:\n",
    "\n",
    "- Are not normally distributed  \n",
    "- Exhibit fat tails (excess kurtosis)  \n",
    "- Contain extreme observations more frequently than predicted by a normal distribution  \n",
    "\n",
    "This result is consistent with well-documented empirical findings in financial econometrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc1856",
   "metadata": {},
   "source": [
    "## Final Conclusion\n",
    "\n",
    "This notebook performed a comprehensive validation and statistical analysis of the processed S&P 500 dataset.\n",
    "\n",
    "The dataset was confirmed to be:\n",
    "\n",
    "- Chronologically ordered  \n",
    "- Free of duplicate observations  \n",
    "- Correctly feature-engineered  \n",
    "- Consistent with expected rolling-window behavior  \n",
    "\n",
    "Rolling NaN values were mathematically justified and confirm proper implementation of moving averages and volatility calculations.\n",
    "\n",
    "Statistical testing confirms well-established stylized facts of financial time series:\n",
    "\n",
    "- Price levels are non-stationary.\n",
    "- Returns are stationary and centered near zero.\n",
    "- Returns exhibit excess kurtosis (fat tails) and reject normality under the Jarque-Bera test.\n",
    "- Volatility varies over time, as observed in rolling volatility and rolling Sharpe ratios.\n",
    "\n",
    "Risk metrics such as maximum drawdown, annualized volatility, and the Sharpe ratio provide quantitative measures of market risk and performance. The time-varying Sharpe ratio further demonstrates that risk-adjusted performance changes across market regimes.\n",
    "\n",
    "Overall, the empirical results align with financial theory and confirm that the dataset is statistically coherent, financially realistic, and suitable for advanced quantitative modeling, econometric analysis, or predictive applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
