{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4fb5b8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "## S&P 500 Historical Data Project\n",
    "\n",
    "This notebook explores historical S&P 500 price data from Investing.com.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Inspect the raw dataset.\n",
    "2. Create a “dirty” version to simulate real-world data issues.\n",
    "3. Explore missing values, duplicates, outliers.\n",
    "4. Visualize trends and distributions.\n",
    "5. Prepare for the cleaning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb09550",
   "metadata": {},
   "source": [
    "## 1. Dataset Description\n",
    "\n",
    "The dataset contains historical S&P 500 price data downloaded from Investing.com.\n",
    "\n",
    "- Original file: `sp500_raw.csv`\n",
    "- Location: `data/raw/`\n",
    "- Columns:\n",
    "  - Date\n",
    "  - Price\n",
    "  - Open\n",
    "  - High\n",
    "  - Low\n",
    "  - Vol. (we will drop this column)\n",
    "  - Change %\n",
    "- Rows: 5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/sp500_raw.csv\")\n",
    "\n",
    "if 'Vol.' in df.columns:\n",
    "    df = df.drop(columns=['Vol.'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093689f6",
   "metadata": {},
   "source": [
    "## 2. Dataset Info\n",
    "\n",
    "Check basic info: shape, data types, missing values, duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c98148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648139a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e90b91a",
   "metadata": {},
   "source": [
    "### 2.1. Convert Columns to Numeric\n",
    "The numeric columns (Price, Open, High, Low) are read as strings because they contain commas.\n",
    "We also convert 'Change %' to float by removing the percent sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Price', 'Open', 'High', 'Low']\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].str.replace(',', '').astype(float)\n",
    "\n",
    "\n",
    "df['Change %'] = df['Change %'].str.replace('%', '').astype(float)\n",
    "\n",
    "df.dtypes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11e9de",
   "metadata": {},
   "source": [
    "## 3. Simulate a Dirty Dataset\n",
    "To demonstrate a cleaning pipeline, we create a dirty dataset with:\n",
    "- Duplicate rows\n",
    "- Missing values\n",
    "- Outliers\n",
    "- Shuffled rows\n",
    "- Column name inconsistencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_dirty = df.copy()\n",
    "\n",
    "duplicates = df_dirty.sample(20, random_state=42)\n",
    "df_dirty = pd.concat([df_dirty, duplicates], ignore_index=True)\n",
    "\n",
    "nan_indices = np.random.choice(df_dirty.index, 30, replace=False)\n",
    "df_dirty.loc[nan_indices, 'Price'] = np.nan\n",
    "\n",
    "outlier_indices = np.random.choice(df_dirty.index, 5, replace=False)\n",
    "df_dirty.loc[outlier_indices, 'High'] *= 5\n",
    "\n",
    "df_dirty = df_dirty.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "df_dirty.columns = [col + \" \" for col in df_dirty.columns]\n",
    "\n",
    "df_dirty.to_csv(\"../data/raw/sp500_dirty.csv\", index=False)\n",
    "\n",
    "df_dirty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df9a2f",
   "metadata": {},
   "source": [
    "## 4. Inspection of the Dirty Dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty = pd.read_csv(\"../data/raw/sp500_dirty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d02c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f4ff6",
   "metadata": {},
   "source": [
    "## 5. Descriptive Statistics\n",
    "Explore basic statistics to detect anomalies/outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4eeca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdfbd9e",
   "metadata": {},
   "source": [
    "## 6. Visualize price trends and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(pd.to_datetime(df_dirty['Date ']), df_dirty['Price '], marker='o', markersize=2)\n",
    "plt.title(\"Price over Time (Dirty Dataset)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df_dirty['Price '].dropna(), bins=50)\n",
    "plt.title(\"Price Distribution (Dirty Dataset)\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aea09b",
   "metadata": {},
   "source": [
    "## 7. Observations\n",
    "- Missing values exist in Price (30 introduced)\n",
    "- Duplicate rows exist (20 introduced)\n",
    "- Outliers in High column\n",
    "- Rows are shuffled\n",
    "- Column names have extra spaces\n",
    "- Dataset is ready for cleaning pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
